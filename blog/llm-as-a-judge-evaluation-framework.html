<!DOCTYPE html><html lang="zh-Hant"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="https://qwer820921.github.io/_next/static/css/f71b761575b48bd6.css" data-precedence="next"/><link rel="stylesheet" href="https://qwer820921.github.io/_next/static/css/e57a9f01512809bb.css" data-precedence="next"/><link rel="stylesheet" href="https://qwer820921.github.io/_next/static/css/4bb1c53d4d41ca49.css" data-precedence="next"/><link rel="stylesheet" href="https://qwer820921.github.io/_next/static/css/45df6ee84bc085cd.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="https://qwer820921.github.io/_next/static/chunks/webpack-c887150ca99864ad.js"/><script src="https://qwer820921.github.io/_next/static/chunks/4bd1b696-e100a0b1879d5e6b.js" async=""></script><script src="https://qwer820921.github.io/_next/static/chunks/1684-9b53760636e10952.js" async=""></script><script src="https://qwer820921.github.io/_next/static/chunks/main-app-c0d2570cf703bee2.js" async=""></script><script src="https://qwer820921.github.io/_next/static/chunks/6283-1586b7e20e5a28d4.js" async=""></script><script src="https://qwer820921.github.io/_next/static/chunks/app/layout-984d35e9d146542e.js" async=""></script><script src="https://qwer820921.github.io/_next/static/chunks/app/blog/%5Bslug%5D/page-bad5b7683d758711.js" async=""></script><link rel="preload" href="https://qwer820921.github.io/_next/static/chunks/2990.e74a1c7b49aeb05a.js" as="script" fetchPriority="low"/><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-CCKVESHCQ1" as="script"/><link rel="preload" href="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2709303513603814" as="script" crossorigin=""/><link rel="icon" href="/favicon.ico"/><link rel="apple-touch-icon" href="/logo192.png"/><link rel="manifest" href="/manifest.json"/><link rel="preload" href="/logo192.png" as="image"/><title>【AI 評測領域】LLM-as-a-Judge：如何用 AI 來面試 AI？ | 子yee 萬事屋 | 子yee</title><meta name="description" content="深入探討 LLM-as-a-Judge 評測框架，教學如何利用高階 LLM 作為考官，自動評估其他 LLM 的輸出品質，實現 AI 應用從原型到產品的關鍵飛躍。"/><meta name="author" content="子yee"/><meta name="keywords" content="子yee 萬事屋, 台股查詢, 自選股, 技術小工具, 股票資訊平台, 技術顧問, 自動化工具"/><meta name="google-site-verification" content="adHIcDQiasHY4YzPlrpmSSPKl7Oj1WxrPJ_4GV4PQcM"/><meta property="og:title" content="【AI 評測領域】LLM-as-a-Judge：如何用 AI 來面試 AI？"/><meta property="og:description" content="深入探討 LLM-as-a-Judge 評測框架，教學如何利用高階 LLM 作為考官，自動評估其他 LLM 的輸出品質，實現 AI 應用從原型到產品的關鍵飛躍。"/><meta property="og:image" content="https://qwer820921.github.io/images/img15.jpg"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="【AI 評測領域】LLM-as-a-Judge：如何用 AI 來面試 AI？"/><meta property="og:type" content="article"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="【AI 評測領域】LLM-as-a-Judge：如何用 AI 來面試 AI？"/><meta name="twitter:description" content="深入探討 LLM-as-a-Judge 評測框架，教學如何利用高階 LLM 作為考官，自動評估其他 LLM 的輸出品質，實現 AI 應用從原型到產品的關鍵飛躍。"/><meta name="twitter:image" content="https://qwer820921.github.io/images/img15.jpg"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="64x64"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="https://qwer820921.github.io/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><main class="container-fluid p-0"><article class="container py-5"><div class="row justify-content-center"><div class="col-12 col-lg-8"><div class="card blogPost_articleCard__LIiRr"><div class="card-body blogPost_cardBody__5xHPD"><header class="blogPost_articleHeader__dQ5vG"><div id="static-back-btn" style="display:inline-flex;margin-bottom:1rem;cursor:pointer;position:relative;z-index:1"><div class="btn d-inline-flex align-items-center gap-2 shadow rounded-pill px-4 py-2 text-decoration-none" role="button" style="pointer-events:auto;background-color:#fff;backdrop-filter:none;border:1px solid rgba(0,0,0,0.08);color:#495057;font-weight:500;transition:all 0.2s ease;cursor:pointer"><span>回到文章列表</span></div></div><h1 class="blogPost_articleTitle__BCXQE">【AI 評測領域】LLM-as-a-Judge：如何用 AI 來面試 AI？</h1><div class="blogPost_articleMeta__1R_wB"><div class="blogPost_metaItem__xpKuj"><i class="bi bi-person-fill blogPost_metaIcon__h8wBb"></i><span class="blogPost_metaLabel__y0uVD">作者:</span>子yee</div><div class="blogPost_metaItem__xpKuj"><i class="bi bi-calendar3 blogPost_metaIcon__h8wBb"></i><span class="blogPost_metaLabel__y0uVD">日期:</span>2026-02-06</div></div></header><div class="blogContent_blogContent__VY_R4"><h2>1. Overview</h2>
<p>在大型語言模型（LLM）應用開發的生命週期中，一個核心且持續存在的挑戰是如何<strong>客觀、高效地評估模型輸出品質</strong>。當我們開發出一個「股票分析 AI」或「遊戲數值 AI」時，如何知道它今天的回答是否比昨天更準確、更符合預期？傳統的人工檢查方法不僅耗時、成本高昂，而且容易受到主觀判斷的影響，難以大規模應用 [1]。這使得 LLM 應用從「玩具專案」跨入「產品級應用」的過程充滿不確定性。</p>
<p>為了解決這一痛點，<strong>「LLM-as-a-Judge」</strong>（將 LLM 作為評審）的評測框架應運而生。其核心思想是利用一個能力更強、更穩定的 LLM（例如 GPT-4o 或 Claude 3.5 Sonnet）作為「考官」，自動評估另一個待測 LLM（例如 Llama 3 或 Phi-4）的輸出品質 [2]。這種方法將評測過程自動化，使得開發者能夠在每次模型更新、提示詞調整或數據集變化後，快速獲得量化的性能反饋，從而實現持續整合與持續部署（CI/CD）的 AI 開發流程。</p>
<p>本文件將深入探討 LLM-as-a-Judge 的概念、架構與實作細節。我們將學習如何設定精確的評分標準（Rubrics），並透過程式碼自動化評測流程，最終產出可視化的測試報告。這不僅是 AI 評測領域的重大突破，更是將 LLM 應用推向產品級成熟度的必經之路。</p>
<h2>2. Architecture / Design</h2>
<p>LLM-as-a-Judge 框架的核心在於將評測任務本身也視為一個 LLM 應用，其中包含明確的角色分工和評測流程。其架構設計旨在模擬人類評審的判斷過程，但以自動化、標準化的方式執行 [3]。</p>
<h3>2.1 核心角色定義</h3>
<p>在 LLM-as-a-Judge 框架中，主要有三個關鍵角色：</p>
<ul>
<li><strong>Candidate (應試者)</strong>：<!-- -->
<ul>
<li><strong>定義</strong>：這是我們希望評估其輸出品質的 LLM 模型、特定的提示詞（Prompt）或整個 AI 應用程式。它可以是較小的、開源的模型（如 Llama 3、Phi-4），或者是針對特定任務微調的模型。</li>
<li><strong>職責</strong>：根據給定的輸入（例如一個問題、一個任務描述），生成一個輸出（例如一個答案、一份報告）。</li>
</ul>
</li>
<li><strong>Judge (考官)</strong>：<!-- -->
<ul>
<li><strong>定義</strong>：一個能力更強、更穩定的 LLM 模型，負責對 Candidate 的輸出進行評估。通常選擇市場上最先進、表現最佳的模型，如 GPT-4o、Claude 3.5 Sonnet [4]。</li>
<li><strong>職責</strong>：接收 Candidate 的輸入、Candidate 的輸出，以及一套明確的評分標準（Rubrics），然後根據這些資訊給出評分和評分理由（通常以思維鏈 Chain-of-Thought 的形式）。</li>
</ul>
</li>
<li><strong>Reference (參考答案 - 可選)</strong>：<!-- -->
<ul>
<li><strong>定義</strong>：對於某些任務，可能存在一個人類編寫的黃金標準答案或一組正確的事實數據。這可以作為 Judge 評估時的額外參考資訊。</li>
<li><strong>職責</strong>：提供客觀的基準，幫助 Judge 更準確地判斷 Candidate 輸出的正確性或品質。並非所有評測場景都必須提供 Reference。</li>
</ul>
</li>
</ul>
<h3>2.2 評測模式</h3>
<p>LLM-as-a-Judge 可以支援多種評測模式，以適應不同的評估需求：</p>
<ul>
<li><strong>Single Output Scoring (單點評分)</strong>：<!-- -->
<ul>
<li><strong>描述</strong>：Judge LLM 接收一個輸入、一個 Candidate 輸出和一套 Rubrics，然後根據 Rubrics 對該輸出進行獨立評分（例如 1 到 5 分）。</li>
<li><strong>適用場景</strong>：評估輸出的連貫性、完整性、語氣、風格等主觀品質。</li>
</ul>
</li>
<li><strong>Pairwise Comparison (兩兩比較)</strong>：<!-- -->
<ul>
<li><strong>描述</strong>：Judge LLM 接收一個輸入和兩個不同 Candidate 模型（或不同提示詞版本）的輸出，然後判斷哪一個輸出更好，或者兩者是否相同 [5]。</li>
<li><strong>適用場景</strong>：比較不同模型或提示詞版本之間的相對性能，特別適用於 A/B 測試。</li>
</ul>
</li>
<li><strong>Binary Classification (二元判斷)</strong>：<!-- -->
<ul>
<li><strong>描述</strong>：Judge LLM 判斷 Candidate 輸出是否符合特定的二元標準（例如 Pass/Fail、True/False）。</li>
<li><strong>適用場景</strong>：評估輸出的事實正確性、安全性（是否包含有害內容）、格式遵循度等客觀標準。</li>
</ul>
</li>
</ul>
<h3>2.3 自動化評測工作流 (Automated Evaluation Workflow)</h3>
<p>一個典型的 LLM-as-a-Judge 自動化評測工作流包含以下步驟：</p>
<ol>
<li><strong>準備測試數據集 (Prepare Test Dataset)</strong>：收集一組代表真實使用場景的輸入數據（例如使用者問題、任務描述）。對於需要 Reference 的評測，也需準備對應的黃金標準答案。</li>
<li><strong>Candidate 模型生成輸出 (Candidate Generation)</strong>：<!-- -->
<ul>
<li>將測試數據集中的每個輸入傳遞給待評測的 Candidate LLM。</li>
<li>收集 Candidate LLM 針對每個輸入生成的輸出。</li>
</ul>
</li>
<li><strong>Judge 模型評分 (Judge Evaluation)</strong>：<!-- -->
<ul>
<li>對於測試數據集中的每個輸入-輸出對，將以下資訊傳遞給 Judge LLM：<!-- -->
<ul>
<li>原始輸入 (Original Input)</li>
<li>Candidate LLM 的輸出 (Candidate Output)</li>
<li>詳細的評分標準 (Rubrics)</li>
<li>（可選）參考答案 (Reference Answer)</li>
</ul>
</li>
<li>Judge LLM 根據這些資訊，生成一個結構化的評分（例如 JSON 格式），其中包含分數和解釋其判斷的理由（Chain-of-Thought）[6]。</li>
</ul>
</li>
<li><strong>數據彙整與分析 (Data Aggregation &amp; Analysis)</strong>：<!-- -->
<ul>
<li>收集所有 Judge LLM 生成的評分結果。</li>
<li>計算各種評測指標的平均分、分佈等統計數據。</li>
<li>分析 Judge LLM 給出的理由，找出 Candidate 模型的優點和缺點。</li>
</ul>
</li>
<li><strong>報告生成與可視化 (Report Generation &amp; Visualization)</strong>：<!-- -->
<ul>
<li>將分析結果整理成易讀的報告，例如包含雷達圖、趨勢圖、分數分佈圖等，直觀展示 Candidate 模型的性能。</li>
<li>這份報告可以作為開發者改進模型的依據。</li>
</ul>
</li>
<li><strong>迭代優化 (Iterative Optimization)</strong>：<!-- -->
<ul>
<li>根據評測報告的結果，開發者調整 Candidate 模型的提示詞、參數或甚至進行微調。</li>
<li>重複上述步驟，直到 Candidate 模型的性能達到預期目標。</li>
</ul>
</li>
</ol>
<h2>3. 評分標準 (Evaluation Rubrics) 設計</h2>
<p>設計一套清晰、客觀且全面的評分標準（Rubrics）是 LLM-as-a-Judge 成功的關鍵。Rubrics 應該明確地告訴 Judge LLM「什麼是好的輸出」，以及不同分數等級的具體含義 [7]。</p>
<h3>3.1 Rubric 結構</h3>
<p>一個有效的 Rubric 通常包含以下要素：</p>
<ul>
<li><strong>Criterion (評測標準)</strong>：定義評估的維度，例如「邏輯連貫性」、「數據準確度」、「語氣合適性」、「格式遵循度」等。</li>
<li><strong>Scale (評分量表)</strong>：定義每個標準的評分範圍（例如 1-5 分），並為每個分數等級提供詳細的描述。例如：<!-- -->
<ul>
<li><strong>5 分 (優秀)</strong>：輸出完全符合要求，無可挑剔。</li>
<li><strong>3 分 (一般)</strong>：輸出基本符合要求，但存在一些小瑕疵。</li>
<li><strong>1 分 (差)</strong>：輸出完全不符合要求，或包含嚴重錯誤。</li>
</ul>
</li>
<li><strong>Examples (範例)</strong>：提供給 Judge LLM 的 Few-shot 範例，展示在不同分數等級下，一個「好」的輸出和一個「壞」的輸出分別是什麼樣子。這有助於 Judge LLM 更好地理解評分標準 [8]。</li>
</ul>
<h3>3.2 關鍵評測指標</h3>
<p>針對 LLM 的輸出，常見的評測指標包括：</p>
<table><thead><tr><th style="text-align:left">指標名稱</th><th style="text-align:left">描述</th><th style="text-align:left">評測方式</th></tr></thead><tbody><tr><td style="text-align:left"><strong>Faithfulness (忠實度)</strong></td><td style="text-align:left">輸出內容是否完全基於提供的原始上下文或資料，沒有產生幻覺。</td><td style="text-align:left">Judge 檢查輸出中的每個事實性陳述是否能在原始輸入中找到依據。</td></tr><tr><td style="text-align:left"><strong>Relevance (相關性)</strong></td><td style="text-align:left">輸出內容是否直接、完整地回答了使用者的問題或完成了任務。</td><td style="text-align:left">Judge 判斷輸出是否偏離主題，或是否遺漏了關鍵資訊。</td></tr><tr><td style="text-align:left"><strong>Correctness (正確性)</strong></td><td style="text-align:left">輸出中包含的事實性數據、邏輯判斷是否準確無誤。</td><td style="text-align:left">Judge 根據 Reference 或其自身知識判斷事實性錯誤。</td></tr><tr><td style="text-align:left"><strong>Coherence (連貫性)</strong></td><td style="text-align:left">輸出內容的邏輯是否清晰、流暢，各部分之間是否有良好的銜接。</td><td style="text-align:left">Judge 評估輸出的組織結構、段落銜接和整體可讀性。</td></tr><tr><td style="text-align:left"><strong>Conciseness (簡潔性)</strong></td><td style="text-align:left">輸出是否在不犧牲資訊完整性的前提下，盡可能地簡潔明瞭。</td><td style="text-align:left">Judge 判斷輸出是否存在冗餘、重複或不必要的細節。</td></tr><tr><td style="text-align:left"><strong>Safety (安全性)</strong></td><td style="text-align:left">輸出是否包含有害、偏見、歧視或不當的內容。</td><td style="text-align:left">Judge 檢查輸出是否違反預設的安全準則。</td></tr></tbody></table>
<h2>4. Prerequisites</h2>
<p>要實作 LLM-as-a-Judge 評測框架，您需要具備以下環境和知識：</p>
<ul>
<li><strong>Python 環境</strong>：建議使用 Python 3.9 或更高版本。</li>
<li><strong>LLM API 存取</strong>：需要至少兩個 LLM 的 API 存取權限：一個作為 Judge（通常是最強的模型，如 GPT-4o），另一個作為 Candidate（待測模型）。</li>
<li><strong>LLM 框架知識</strong>：熟悉 LangChain、DSPy 或 Semantic Kernel 等 LLM 開發框架，以便於構建 Candidate 和 Judge 的互動邏輯。</li>
<li><strong>數據處理能力</strong>：能夠處理測試數據集，包括輸入、輸出和可選的參考答案。</li>
<li><strong>評估框架</strong>：了解並可能需要使用專門的 LLM 評估框架，如 G-Eval、Prometheus 或 DeepEval。</li>
<li><strong>數據可視化工具</strong>：熟悉 Matplotlib、Seaborn 或其他數據可視化庫，用於生成評測報告。</li>
</ul>
<h2>5. Implementation / Code Example</h2>
<p>本節將提供一個概念性的 Python 程式碼範例，展示如何使用 LLM-as-a-Judge 評估一個簡單的「股票分析 AI」的回答品質。我們將使用一個較小的模型作為 Candidate，並使用 GPT-4o 作為 Judge。</p>
<h3>5.1 專案初始化與安裝</h3>
<pre><code class="language-bash">mkdir llm-judge-example
cd llm-judge-example
pip install openai python-dotenv # 假設使用 OpenAI API
</code></pre>
<h3>5.2 配置 LLM API 金鑰</h3>
<p>創建 <code>.env</code> 檔案來儲存您的 API 金鑰：</p>
<pre><code class="language-dotenv">OPENAI_API_KEY=your_openai_api_key_here
</code></pre>
<h3>5.3 核心程式碼 (<code>evaluate_stock_ai.py</code>)</h3>
<pre><code class="language-python">import os
import json
from dotenv import load_dotenv
from openai import OpenAI
from typing import List, Dict, Any

load_dotenv()

# 配置 OpenAI 客戶端
client = OpenAI(api_key=os.getenv(&quot;OPENAI_API_KEY&quot;))

# 1. 定義評分標準 (Rubrics)
# 這裡的 Rubric 會被直接傳遞給 Judge LLM
EVALUATION_RUBRIC = &quot;&quot;&quot;
你是一個專業的股票分析師，請根據以下標準評估 AI 提供的股票分析報告：

評分標準 (請以 JSON 格式輸出):
{
  &quot;logic_score&quot;: &quot;1-5&quot;, // 邏輯性：1分(差) - 5分(優秀)
  &quot;data_accuracy&quot;: &quot;Pass/Fail&quot;, // 數據準確度：是否包含錯誤數據
  &quot;completeness&quot;: &quot;1-5&quot;, // 完整性：1分(差) - 5分(優秀)
  &quot;reasoning&quot;: &quot;string&quot;, // 評分理由，詳細說明每個分數的依據
  &quot;overall_verdict&quot;: &quot;string&quot; // 總體評價
}

請根據以下股票分析報告和原始問題進行評估。

原始問題: {question}
AI 分析報告: {ai_response}

請嚴格按照 JSON 格式輸出評分，並提供詳細的理由。
&quot;&quot;&quot;

# 2. 模擬 Candidate LLM (股票分析 AI)
# 在實際應用中，這會是一個真實的 LLM 調用，可能是較小的模型或特定提示詞
def candidate_stock_analyzer(question: str) -&gt; str:
    # 這裡模擬一個簡單的 LLM 回應，可能包含一些不準確或不完整的資訊
    if &quot;AAPL&quot; in question:
        return &quot;蘋果公司 (AAPL) 是一家科技巨頭，其股價受到 iPhone 銷量和服務收入的影響。最近的財報顯示 iPhone 銷量略有下降，但服務收入增長強勁。預計未來股價將保持穩定，但長期增長潛力有限。&quot; # 故意寫得有點模糊
    elif &quot;TSLA&quot; in question:
        return &quot;特斯拉 (TSLA) 是電動車市場的領導者，但面臨來自傳統車廠的激烈競爭。其股價波動較大，受馬斯克言論和生產目標影響。最近的生產數據顯示增長放緩，但新工廠投產可能帶來轉機。&quot; # 故意寫得有點通用
    else:
        return &quot;我無法提供關於該股票的詳細分析。&quot;

# 3. Judge LLM 進行評估
def judge_llm_evaluation(question: str, ai_response: str) -&gt; Dict[str, Any]:
    judge_prompt = EVALUATION_RUBRIC.format(question=question, ai_response=ai_response)

    try:
        response = client.chat.completions.create(
            model=&quot;gpt-4o&quot;, # 使用最強的模型作為考官
            messages=[
                {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是一個嚴格且公正的股票分析師評審。&quot;},
                {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: judge_prompt}
            ],
            response_format={&quot;type&quot;: &quot;json_object&quot;}, # 強制輸出 JSON 格式
            temperature=0.0 # 確保評分穩定性
        )
        evaluation_result = json.loads(response.choices[0].message.content)
        return evaluation_result
    except Exception as e:
        print(f&quot;Judge LLM 評估失敗: {e}&quot;)
        return {&quot;error&quot;: str(e), &quot;reasoning&quot;: &quot;Judge LLM 無法生成有效評分&quot;}

# 4. 運行評測工作流
async def main():
    test_cases = [
        {&quot;question&quot;: &quot;請分析蘋果公司 (AAPL) 的近期股價走勢和未來預期。&quot;, &quot;expected_data_accuracy&quot;: &quot;Pass&quot;},
        {&quot;question&quot;: &quot;請分析特斯拉 (TSLA) 的競爭優勢和市場挑戰。&quot;, &quot;expected_data_accuracy&quot;: &quot;Pass&quot;},
        {&quot;question&quot;: &quot;請分析 Google (GOOG) 的雲端業務發展。&quot;, &quot;expected_data_accuracy&quot;: &quot;Fail&quot;}, # 預期 Candidate 無法提供詳細分析
    ]

    all_evaluations = []

    print(&quot;--- 開始 LLM-as-a-Judge 評測 ---&quot;)
    for i, test_case in enumerate(test_cases):
        question = test_case[&quot;question&quot;]
        print(f&quot;\n[測試案例 {i+1}] 問題: {question}&quot;)

        # Candidate LLM 生成回應
        candidate_response = candidate_stock_analyzer(question)
        print(f&quot;[Candidate AI] 回應: {candidate_response}&quot;)

        # Judge LLM 進行評估
        evaluation = judge_llm_evaluation(question, candidate_response)
        print(f&quot;[Judge AI] 評估結果: {json.dumps(evaluation, indent=2)}&quot;)
        all_evaluations.append(evaluation)

    print(&quot;\n--- 評測報告摘要 ---&quot;)
    total_logic_score = 0
    pass_data_accuracy = 0
    total_completeness_score = 0
    evaluated_count = 0

    for eval_result in all_evaluations:
        if &quot;logic_score&quot; in eval_result and isinstance(eval_result[&quot;logic_score&quot;], (int, str)):
            try:
                total_logic_score += int(eval_result[&quot;logic_score&quot;])
                evaluated_count += 1
            except ValueError:
                pass # 忽略無效分數

        if eval_result.get(&quot;data_accuracy&quot;) == &quot;Pass&quot;:
            pass_data_accuracy += 1

        if &quot;completeness&quot; in eval_result and isinstance(eval_result[&quot;completeness&quot;], (int, str)):
            try:
                total_completeness_score += int(eval_result[&quot;completeness&quot;])
            except ValueError:
                pass # 忽略無效分數

    if evaluated_count &gt; 0:
        print(f&quot;平均邏輯性分數: {total_logic_score / evaluated_count:.2f}&quot;)
        print(f&quot;數據準確度通過率: {pass_data_accuracy / len(test_cases):.2%}&quot;)
        print(f&quot;平均完整性分數: {total_completeness_score / evaluated_count:.2f}&quot;)
    else:
        print(&quot;沒有有效的評估結果。&quot;)

    print(&quot;--- 評測完成 ---&quot;)

if __name__ == &quot;__main__&quot;:
    import asyncio
    asyncio.run(main())
</code></pre>
<h3>5.4 程式碼說明</h3>
<ul>
<li><strong><code>EVALUATION_RUBRIC</code></strong>：這是一個多行字串，定義了給 Judge LLM 的評分標準。它明確要求 Judge 以 JSON 格式輸出，並包含 <code>logic_score</code>、<code>data_accuracy</code>、<code>completeness</code>、<code>reasoning</code> 和 <code>overall_verdict</code> 等欄位。這是 LLM-as-a-Judge 的核心，將人類的評分邏輯轉化為 AI 可理解的指令 [7]。</li>
<li><strong><code>candidate_stock_analyzer</code></strong>：模擬一個待評測的股票分析 AI。在實際應用中，這會是一個對您自己開發的 LLM 應用程式的 API 調用，或者是一個使用較小模型（如 Llama 3）的推理過程。</li>
<li><strong><code>judge_llm_evaluation</code></strong>：這是 Judge LLM 的核心功能。它使用 <code>gpt-4o</code> 作為考官，接收原始問題和 Candidate 的回應，並根據 <code>EVALUATION_RUBRIC</code> 進行評估。<code>response_format={&quot;type&quot;: &quot;json_object&quot;}</code> 強制 LLM 輸出 JSON 格式，確保結果的可解析性 [6]。<code>temperature=0.0</code> 則用於減少 Judge LLM 的隨機性，使其評分更穩定。</li>
<li><strong><code>main</code> 函數</strong>：定義了一組測試案例，並循環執行評測工作流。它首先呼叫 <code>candidate_stock_analyzer</code> 獲取回應，然後將回應傳遞給 <code>judge_llm_evaluation</code> 進行評分。最後，它彙總並列印出評測報告摘要。</li>
</ul>
<h2>6. Parameters / API Reference</h2>
<p>本節將基於上述範例，抽象出實作 LLM-as-a-Judge 時可能涉及的關鍵參數和介面。</p>
<h3>6.1 <code>EVALUATION_RUBRIC</code> 結構 (傳遞給 Judge LLM 的提示詞)</h3>
<table><thead><tr><th style="text-align:left">欄位名稱</th><th style="text-align:left">類型</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left"><code>logic_score</code></td><td style="text-align:left"><code>int</code></td><td style="text-align:left">評估輸出的邏輯性，通常為 1-5 分。</td></tr><tr><td style="text-align:left"><code>data_accuracy</code></td><td style="text-align:left"><code>str</code></td><td style="text-align:left">評估數據的準確度，通常為 &quot;Pass&quot; 或 &quot;Fail&quot;。</td></tr><tr><td style="text-align:left"><code>completeness</code></td><td style="text-align:left"><code>int</code></td><td style="text-align:left">評估輸出的完整性，通常為 1-5 分。</td></tr><tr><td style="text-align:left"><code>reasoning</code></td><td style="text-align:left"><code>str</code></td><td style="text-align:left">Judge LLM 給出評分的詳細理由（Chain-of-Thought）。</td></tr><tr><td style="text-align:left"><code>overall_verdict</code></td><td style="text-align:left"><code>str</code></td><td style="text-align:left">Judge LLM 對輸出的總體評價。</td></tr></tbody></table>
<h3>6.2 <code>candidate_stock_analyzer</code> 介面 (概念性)</h3>
<table><thead><tr><th style="text-align:left">參數名稱</th><th style="text-align:left">類型</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left"><code>question</code></td><td style="text-align:left"><code>str</code></td><td style="text-align:left">使用者提出的股票分析問題。</td></tr><tr><td style="text-align:left"><strong>返回值</strong></td><td style="text-align:left"><code>str</code></td><td style="text-align:left">Candidate LLM 生成的股票分析報告。</td></tr></tbody></table>
<h3>6.3 <code>judge_llm_evaluation</code> 介面</h3>
<table><thead><tr><th style="text-align:left">參數名稱</th><th style="text-align:left">類型</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left"><code>question</code></td><td style="text-align:left"><code>str</code></td><td style="text-align:left">原始問題，作為 Judge LLM 評估的上下文。</td></tr><tr><td style="text-align:left"><code>ai_response</code></td><td style="text-align:left"><code>str</code></td><td style="text-align:left">Candidate LLM 生成的分析報告。</td></tr><tr><td style="text-align:left"><strong>返回值</strong></td><td style="text-align:left"><code>Dict[str, Any]</code></td><td style="text-align:left">Judge LLM 根據 Rubric 生成的 JSON 格式評估結果。</td></tr></tbody></table>
<h2>7. Notes &amp; Best Practices</h2>
<ol>
<li><strong>選擇合適的 Judge LLM</strong>：始終選擇當前能力最強、最穩定的 LLM 作為 Judge。其推理能力和遵循指令的能力直接影響評測結果的可靠性。GPT-4o 或 Claude 3.5 Sonnet 是目前較好的選擇 [4]。</li>
<li><strong>設計清晰的 Rubrics</strong>：評分標準必須極其清晰、具體，並包含詳細的評分量表描述和範例。模糊的 Rubrics 會導致 Judge LLM 評分不一致或不準確 [7]。</li>
<li><strong>強制結構化輸出</strong>：要求 Judge LLM 以 JSON 或其他結構化格式輸出評分結果，這便於後續的程式化解析和數據分析。利用 <code>response_format</code> 參數（如 OpenAI API）可以有效實現這一點 [6]。</li>
<li><strong>利用 Chain-of-Thought (CoT)</strong>：在提示詞中要求 Judge LLM 提供其評分理由（Reasoning）。這不僅增加了評測過程的透明度，也幫助開發者理解 Candidate 模型失敗的原因，從而更好地進行調試和改進 [6]。</li>
<li><strong>溫度參數設置</strong>：將 Judge LLM 的 <code>temperature</code> 參數設置為 0.0 或接近 0，以減少其生成結果的隨機性，確保評分的一致性和穩定性。</li>
<li><strong>評測數據集的代表性</strong>：確保測試數據集能夠全面覆蓋 Candidate LLM 的預期使用場景和邊界情況。數據集的品質直接影響評測結果的有效性。</li>
<li><strong>人類校驗 (Human Validation)</strong>：即使是 LLM-as-a-Judge，也建議定期進行小規模的人工校驗，以確保 Judge LLM 的評分與人類專家的判斷保持一致。這有助於發現 Judge LLM 可能存在的偏見或理解偏差 [1]。</li>
<li><strong>成本與效率平衡</strong>：使用最強的 LLM 作為 Judge 可能會產生較高的 API 成本。在實際應用中，可以考慮分層評測：先用較便宜的 Judge 進行初步篩選，再用最強的 Judge 進行關鍵評估，或者對評測頻率進行控制。</li>
</ol>
<h2>8. 為什麼選擇這種方式？</h2>
<p>將 LLM 作為評審（LLM-as-a-Judge）是 AI 應用開發從「玩具」走向「產品」的關鍵一步，其核心價值在於：</p>
<ol>
<li><strong>實現 AI 評測的自動化與規模化</strong>：傳統的人工評測耗時耗力，難以應對快速迭代的 LLM 應用。LLM-as-a-Judge 能夠在數分鐘內完成數百甚至數千個輸出的評測，極大地提升了評測效率，使得開發者能夠在每次代碼提交後都運行完整的評測，實現持續整合與持續部署（CI/CD）的 AI 開發流程 [1]。</li>
<li><strong>提供客觀且一致的評分標準</strong>：人類評審容易受到疲勞、情緒和主觀判斷的影響，導致評分不一致。而經過精心設計提示詞的 Judge LLM，能夠始終如一地遵循預設的 Rubrics 進行評分，提供更客觀、更穩定的評測結果 [7]。</li>
<li><strong>加速模型迭代與優化</strong>：透過自動化評測，開發者可以快速獲得關於模型性能的量化反饋。Judge LLM 提供的詳細評分理由（Chain-of-Thought）能夠幫助開發者精確定位 Candidate 模型的弱點，從而更有針對性地調整提示詞、模型參數或進行微調，加速模型的迭代和優化過程 [6]。</li>
<li><strong>降低評測成本</strong>：雖然使用高階 LLM 作為 Judge 會產生 API 費用，但相較於聘請大量人類專家進行大規模評測，其總體成本通常會顯著降低。這使得中小型團隊也能負擔得起高品質的 AI 評測 [1]。</li>
<li><strong>提升產品級應用的信心</strong>：在將 AI 應用部署到生產環境之前，開發者需要對其性能有足夠的信心。LLM-as-a-Judge 提供了一個可靠的、可重複的評測框架，確保每次發布的模型都達到了預期的品質標準，從而提升了產品的穩定性和使用者滿意度。</li>
</ol>
<hr/>
<p><strong>參考資料</strong></p>
<ul>
<li>[1] Monte Carlo Data. (2025, November 7). <em>LLM-As-Judge: 7 Best Practices &amp; Evaluation Templates</em>. Retrieved from <a href="https://www.montecarlodata.com/blog-llm-as-judge/">https://www.montecarlodata.com/blog-llm-as-judge/</a></li>
<li>[2] Confident AI. (n.d.). <em>LLM-as-a-Judge Simply Explained: The Complete Guide to Run LLM Evaluations</em>. Retrieved from <a href="https://www.confident-ai.com/blog/why-llm-as-a-judge-is-the-best-llm-evaluation-method">https://www.confident-ai.com/blog/why-llm-as-a-judge-is-the-best-llm-evaluation-method</a></li>
<li>[3] Evidently AI. (2025, July 23). <em>LLM-as-a-judge: a complete guide to using LLMs for evaluations</em>. Retrieved from <a href="https://www.evidentlyai.com/llm-guide/llm-as-a-judge">https://www.evidentlyai.com/llm-guide/llm-as-a-judge</a></li>
<li>[4] arXiv. (2024, November 23). <em>A Survey on LLM-as-a-Judge</em>. Retrieved from <a href="https://arxiv.org/html/2411.15594v1">https://arxiv.org/html/2411.15594v1</a></li>
<li>[5] Reddit. (2026, January 6). <em>BEST LLM-as-a-Judge Practices from 2025</em>. Retrieved from <a href="https://www.reddit.com/r/LangChain/comments/1q59at8/best_llmasajudge_practices_from_2025/">https://www.reddit.com/r/LangChain/comments/1q59at8/best_llmasajudge_practices_from_2025/</a></li>
<li>[6] Confident AI. (2025, October 10). <em>G-Eval Simply Explained: LLM-as-a-Judge for LLM Evaluation</em>. Retrieved from <a href="https://www.confident-ai.com/blog/g-eval-the-definitive-guide">https://www.confident-ai.com/blog/g-eval-the-definitive-guide</a></li>
<li>[7] Towards Data Science. (2025, June 19). <em>LLM-as-a-Judge: A Practical Guide</em>. Retrieved from <a href="https://towardsdatascience.com/llm-as-a-judge-a-practical-guide/">https://towardsdatascience.com/llm-as-a-judge-a-practical-guide/</a></li>
<li>[8] Microsoft Learn. (2024, June 24). <em>Evaluating the performance of LLM summarization prompts with G-Eval</em>. Retrieved from <a href="https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/generative-ai/working-with-llms/evaluation/g-eval-metric-for-summarization">https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/generative-ai/working-with-llms/evaluation/g-eval-metric-for-summarization</a></li>
</ul></div></div></div></div></div></article><!--$--><!--/$--><!--$--><!--/$--></main><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><noscript>You need to enable JavaScript to run this app.</noscript><div class="position-fixed" style="z-index:1050;bottom:20px;right:20px;transform:translate(0px, 0px);touch-action:none;cursor:default;display:flex;flex-direction:column;align-items:flex-end;transition:transform 0.3s ease"><div class="position-relative"><button class="btn rounded-circle d-flex align-items-center justify-content-center shadow-lg" style="width:60px;height:60px;cursor:grab;background:linear-gradient(135deg, #0d6efd, #0a58ca);border:2px solid rgba(255,255,255,0.2);transition:transform 0.2s ease" aria-label="切換聊天視窗"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="white" style="width:28px;height:28px;pointer-events:none"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-5l-5 5v-5z"></path></svg></button><span class="position-absolute bg-danger rounded-circle" style="width:12px;height:12px;top:0;right:0;border:2px solid white"></span></div></div><script src="https://qwer820921.github.io/_next/static/chunks/webpack-c887150ca99864ad.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[69243,[\"6283\",\"static/chunks/6283-1586b7e20e5a28d4.js\",\"7177\",\"static/chunks/app/layout-984d35e9d146542e.js\"],\"\"]\n3:I[6476,[\"6283\",\"static/chunks/6283-1586b7e20e5a28d4.js\",\"7177\",\"static/chunks/app/layout-984d35e9d146542e.js\"],\"default\"]\n4:I[87555,[],\"\"]\n5:I[31295,[],\"\"]\n6:I[39543,[\"6283\",\"static/chunks/6283-1586b7e20e5a28d4.js\",\"7177\",\"static/chunks/app/layout-984d35e9d146542e.js\"],\"default\"]\n8:I[59665,[],\"MetadataBoundary\"]\na:I[59665,[],\"OutletBoundary\"]\nd:I[74911,[],\"AsyncMetadataOutlet\"]\nf:I[59665,[],\"ViewportBoundary\"]\n11:I[26614,[],\"\"]\n:HL[\"https://qwer820921.github.io/_next/static/css/f71b761575b48bd6.css\",\"style\"]\n:HL[\"https://qwer820921.github.io/_next/static/css/e57a9f01512809bb.css\",\"style\"]\n:HL[\"https://qwer820921.github.io/_next/static/css/4bb1c53d4d41ca49.css\",\"style\"]\n:HL[\"https://qwer820921.github.io/_next/static/css/45df6ee84bc085cd.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"EhClD8Sz3TwW-Ci0ag0BD\",\"p\":\"https://qwer820921.github.io\",\"c\":[\"\",\"blog\",\"llm-as-a-judge-evaluation-framework\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"llm-as-a-judge-evaluation-framework\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"https://qwer820921.github.io/_next/static/css/f71b761575b48bd6.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"https://qwer820921.github.io/_next/static/css/e57a9f01512809bb.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"https://qwer820921.github.io/_next/static/css/4bb1c53d4d41ca49.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"zh-Hant\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/favicon.ico\"}],[\"$\",\"link\",null,{\"rel\":\"apple-touch-icon\",\"href\":\"/logo192.png\"}],[\"$\",\"link\",null,{\"rel\":\"manifest\",\"href\":\"/manifest.json\"}],[\"$\",\"link\",null,{\"rel\":\"preload\",\"href\":\"/logo192.png\",\"as\":\"image\"}],[\"$\",\"$L2\",null,{\"async\":true,\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-CCKVESHCQ1\"}],[\"$\",\"$L2\",null,{\"id\":\"google-analytics\",\"children\":\"\\n            window.dataLayer = window.dataLayer || [];\\n            function gtag(){dataLayer.push(arguments);}\\n            gtag('js', new Date());\\n            gtag('config', 'G-CCKVESHCQ1');\\n          \"}],[\"$\",\"$L2\",null,{\"async\":true,\"src\":\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2709303513603814\",\"crossOrigin\":\"anonymous\"}]]}],[\"$\",\"body\",null,{\"children\":[[\"$\",\"$L3\",null,{\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"$L6\",null,{}]]}]]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"llm-as-a-judge-evaluation-framework\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L7\",[\"$\",\"$L8\",null,{\"children\":\"$L9\"}],[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"https://qwer820921.github.io/_next/static/css/45df6ee84bc085cd.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$La\",null,{\"children\":[\"$Lb\",\"$Lc\",[\"$\",\"$Ld\",null,{\"promise\":\"$@e\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"_Q_bW5WilML47Fl9W8i7N\",{\"children\":[[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],null]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"12:\"$Sreact.suspense\"\n13:I[74911,[],\"AsyncMetadata\"]\n9:[\"$\",\"$12\",null,{\"fallback\":null,\"children\":[\"$\",\"$L13\",null,{\"promise\":\"$@14\"}]}]\n"])</script><script>self.__next_f.push([1,"15:I[57113,[\"5953\",\"static/chunks/app/blog/%5Bslug%5D/page-bad5b7683d758711.js\"],\"default\"]\nc:null\n7:[\"$\",\"article\",null,{\"className\":\"container py-5\",\"children\":[[\"$\",\"div\",null,{\"className\":\"row justify-content-center\",\"children\":[\"$\",\"div\",null,{\"className\":\"col-12 col-lg-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"card blogPost_articleCard__LIiRr\",\"children\":[\"$\",\"div\",null,{\"className\":\"card-body blogPost_cardBody__5xHPD\",\"children\":[[\"$\",\"header\",null,{\"className\":\"blogPost_articleHeader__dQ5vG\",\"children\":[[\"$\",\"$L15\",null,{\"mode\":\"static\",\"id\":\"static-back-btn\"}],[\"$\",\"h1\",null,{\"className\":\"blogPost_articleTitle__BCXQE\",\"children\":\"【AI 評測領域】LLM-as-a-Judge：如何用 AI 來面試 AI？\"}],[\"$\",\"div\",null,{\"className\":\"blogPost_articleMeta__1R_wB\",\"children\":[[\"$\",\"div\",null,{\"className\":\"blogPost_metaItem__xpKuj\",\"children\":[[\"$\",\"i\",null,{\"className\":\"bi bi-person-fill blogPost_metaIcon__h8wBb\"}],[\"$\",\"span\",null,{\"className\":\"blogPost_metaLabel__y0uVD\",\"children\":\"作者:\"}],\"子yee\"]}],[\"$\",\"div\",null,{\"className\":\"blogPost_metaItem__xpKuj\",\"children\":[[\"$\",\"i\",null,{\"className\":\"bi bi-calendar3 blogPost_metaIcon__h8wBb\"}],[\"$\",\"span\",null,{\"className\":\"blogPost_metaLabel__y0uVD\",\"children\":\"日期:\"}],\"2026-02-06\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"blogContent_blogContent__VY_R4\",\"children\":\"$L16\"}]]}]}]}]}],[\"$\",\"$L15\",null,{\"mode\":\"floating\",\"targetId\":\"static-back-btn\"}]]}]\n"])</script><script>self.__next_f.push([1,"17:T14bf,"])</script><script>self.__next_f.push([1,"import os\nimport json\nfrom dotenv import load_dotenv\nfrom openai import OpenAI\nfrom typing import List, Dict, Any\n\nload_dotenv()\n\n# 配置 OpenAI 客戶端\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# 1. 定義評分標準 (Rubrics)\n# 這裡的 Rubric 會被直接傳遞給 Judge LLM\nEVALUATION_RUBRIC = \"\"\"\n你是一個專業的股票分析師，請根據以下標準評估 AI 提供的股票分析報告：\n\n評分標準 (請以 JSON 格式輸出):\n{\n  \"logic_score\": \"1-5\", // 邏輯性：1分(差) - 5分(優秀)\n  \"data_accuracy\": \"Pass/Fail\", // 數據準確度：是否包含錯誤數據\n  \"completeness\": \"1-5\", // 完整性：1分(差) - 5分(優秀)\n  \"reasoning\": \"string\", // 評分理由，詳細說明每個分數的依據\n  \"overall_verdict\": \"string\" // 總體評價\n}\n\n請根據以下股票分析報告和原始問題進行評估。\n\n原始問題: {question}\nAI 分析報告: {ai_response}\n\n請嚴格按照 JSON 格式輸出評分，並提供詳細的理由。\n\"\"\"\n\n# 2. 模擬 Candidate LLM (股票分析 AI)\n# 在實際應用中，這會是一個真實的 LLM 調用，可能是較小的模型或特定提示詞\ndef candidate_stock_analyzer(question: str) -\u003e str:\n    # 這裡模擬一個簡單的 LLM 回應，可能包含一些不準確或不完整的資訊\n    if \"AAPL\" in question:\n        return \"蘋果公司 (AAPL) 是一家科技巨頭，其股價受到 iPhone 銷量和服務收入的影響。最近的財報顯示 iPhone 銷量略有下降，但服務收入增長強勁。預計未來股價將保持穩定，但長期增長潛力有限。\" # 故意寫得有點模糊\n    elif \"TSLA\" in question:\n        return \"特斯拉 (TSLA) 是電動車市場的領導者，但面臨來自傳統車廠的激烈競爭。其股價波動較大，受馬斯克言論和生產目標影響。最近的生產數據顯示增長放緩，但新工廠投產可能帶來轉機。\" # 故意寫得有點通用\n    else:\n        return \"我無法提供關於該股票的詳細分析。\"\n\n# 3. Judge LLM 進行評估\ndef judge_llm_evaluation(question: str, ai_response: str) -\u003e Dict[str, Any]:\n    judge_prompt = EVALUATION_RUBRIC.format(question=question, ai_response=ai_response)\n\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-4o\", # 使用最強的模型作為考官\n            messages=[\n                {\"role\": \"system\", \"content\": \"你是一個嚴格且公正的股票分析師評審。\"},\n                {\"role\": \"user\", \"content\": judge_prompt}\n            ],\n            response_format={\"type\": \"json_object\"}, # 強制輸出 JSON 格式\n            temperature=0.0 # 確保評分穩定性\n        )\n        evaluation_result = json.loads(response.choices[0].message.content)\n        return evaluation_result\n    except Exception as e:\n        print(f\"Judge LLM 評估失敗: {e}\")\n        return {\"error\": str(e), \"reasoning\": \"Judge LLM 無法生成有效評分\"}\n\n# 4. 運行評測工作流\nasync def main():\n    test_cases = [\n        {\"question\": \"請分析蘋果公司 (AAPL) 的近期股價走勢和未來預期。\", \"expected_data_accuracy\": \"Pass\"},\n        {\"question\": \"請分析特斯拉 (TSLA) 的競爭優勢和市場挑戰。\", \"expected_data_accuracy\": \"Pass\"},\n        {\"question\": \"請分析 Google (GOOG) 的雲端業務發展。\", \"expected_data_accuracy\": \"Fail\"}, # 預期 Candidate 無法提供詳細分析\n    ]\n\n    all_evaluations = []\n\n    print(\"--- 開始 LLM-as-a-Judge 評測 ---\")\n    for i, test_case in enumerate(test_cases):\n        question = test_case[\"question\"]\n        print(f\"\\n[測試案例 {i+1}] 問題: {question}\")\n\n        # Candidate LLM 生成回應\n        candidate_response = candidate_stock_analyzer(question)\n        print(f\"[Candidate AI] 回應: {candidate_response}\")\n\n        # Judge LLM 進行評估\n        evaluation = judge_llm_evaluation(question, candidate_response)\n        print(f\"[Judge AI] 評估結果: {json.dumps(evaluation, indent=2)}\")\n        all_evaluations.append(evaluation)\n\n    print(\"\\n--- 評測報告摘要 ---\")\n    total_logic_score = 0\n    pass_data_accuracy = 0\n    total_completeness_score = 0\n    evaluated_count = 0\n\n    for eval_result in all_evaluations:\n        if \"logic_score\" in eval_result and isinstance(eval_result[\"logic_score\"], (int, str)):\n            try:\n                total_logic_score += int(eval_result[\"logic_score\"])\n                evaluated_count += 1\n            except ValueError:\n                pass # 忽略無效分數\n\n        if eval_result.get(\"data_accuracy\") == \"Pass\":\n            pass_data_accuracy += 1\n\n        if \"completeness\" in eval_result and isinstance(eval_result[\"completeness\"], (int, str)):\n            try:\n                total_completeness_score += int(eval_result[\"completeness\"])\n            except ValueError:\n                pass # 忽略無效分數\n\n    if evaluated_count \u003e 0:\n        print(f\"平均邏輯性分數: {total_logic_score / evaluated_count:.2f}\")\n        print(f\"數據準確度通過率: {pass_data_accuracy / len(test_cases):.2%}\")\n        print(f\"平均完整性分數: {total_completeness_score / evaluated_count:.2f}\")\n    else:\n        print(\"沒有有效的評估結果。\")\n\n    print(\"--- 評測完成 ---\")\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())\n"])</script><script>self.__next_f.push([1,"16:[[\"$\",\"h2\",null,{\"children\":\"1. Overview\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"在大型語言模型（LLM）應用開發的生命週期中，一個核心且持續存在的挑戰是如何\",[\"$\",\"strong\",null,{\"children\":\"客觀、高效地評估模型輸出品質\"}],\"。當我們開發出一個「股票分析 AI」或「遊戲數值 AI」時，如何知道它今天的回答是否比昨天更準確、更符合預期？傳統的人工檢查方法不僅耗時、成本高昂，而且容易受到主觀判斷的影響，難以大規模應用 [1]。這使得 LLM 應用從「玩具專案」跨入「產品級應用」的過程充滿不確定性。\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"為了解決這一痛點，\",[\"$\",\"strong\",null,{\"children\":\"「LLM-as-a-Judge」\"}],\"（將 LLM 作為評審）的評測框架應運而生。其核心思想是利用一個能力更強、更穩定的 LLM（例如 GPT-4o 或 Claude 3.5 Sonnet）作為「考官」，自動評估另一個待測 LLM（例如 Llama 3 或 Phi-4）的輸出品質 [2]。這種方法將評測過程自動化，使得開發者能夠在每次模型更新、提示詞調整或數據集變化後，快速獲得量化的性能反饋，從而實現持續整合與持續部署（CI/CD）的 AI 開發流程。\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"本文件將深入探討 LLM-as-a-Judge 的概念、架構與實作細節。我們將學習如何設定精確的評分標準（Rubrics），並透過程式碼自動化評測流程，最終產出可視化的測試報告。這不僅是 AI 評測領域的重大突破，更是將 LLM 應用推向產品級成熟度的必經之路。\"}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"2. Architecture / Design\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"LLM-as-a-Judge 框架的核心在於將評測任務本身也視為一個 LLM 應用，其中包含明確的角色分工和評測流程。其架構設計旨在模擬人類評審的判斷過程，但以自動化、標準化的方式執行 [3]。\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"2.1 核心角色定義\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"在 LLM-as-a-Judge 框架中，主要有三個關鍵角色：\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Candidate (應試者)\"}],\"：\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"定義\"}],\"：這是我們希望評估其輸出品質的 LLM 模型、特定的提示詞（Prompt）或整個 AI 應用程式。它可以是較小的、開源的模型（如 Llama 3、Phi-4），或者是針對特定任務微調的模型。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"職責\"}],\"：根據給定的輸入（例如一個問題、一個任務描述），生成一個輸出（例如一個答案、一份報告）。\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Judge (考官)\"}],\"：\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"定義\"}],\"：一個能力更強、更穩定的 LLM 模型，負責對 Candidate 的輸出進行評估。通常選擇市場上最先進、表現最佳的模型，如 GPT-4o、Claude 3.5 Sonnet [4]。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"職責\"}],\"：接收 Candidate 的輸入、Candidate 的輸出，以及一套明確的評分標準（Rubrics），然後根據這些資訊給出評分和評分理由（通常以思維鏈 Chain-of-Thought 的形式）。\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Reference (參考答案 - 可選)\"}],\"：\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"定義\"}],\"：對於某些任務，可能存在一個人類編寫的黃金標準答案或一組正確的事實數據。這可以作為 Judge 評估時的額外參考資訊。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"職責\"}],\"：提供客觀的基準，幫助 Judge 更準確地判斷 Candidate 輸出的正確性或品質。並非所有評測場景都必須提供 Reference。\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"2.2 評測模式\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"LLM-as-a-Judge 可以支援多種評測模式，以適應不同的評估需求：\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Single Output Scoring (單點評分)\"}],\"：\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"描述\"}],\"：Judge LLM 接收一個輸入、一個 Candidate 輸出和一套 Rubrics，然後根據 Rubrics 對該輸出進行獨立評分（例如 1 到 5 分）。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"適用場景\"}],\"：評估輸出的連貫性、完整性、語氣、風格等主觀品質。\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Pairwise Comparison (兩兩比較)\"}],\"：\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"描述\"}],\"：Judge LLM 接收一個輸入和兩個不同 Candidate 模型（或不同提示詞版本）的輸出，然後判斷哪一個輸出更好，或者兩者是否相同 [5]。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"適用場景\"}],\"：比較不同模型或提示詞版本之間的相對性能，特別適用於 A/B 測試。\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Binary Classification (二元判斷)\"}],\"：\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"描述\"}],\"：Judge LLM 判斷 Candidate 輸出是否符合特定的二元標準（例如 Pass/Fail、True/False）。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"適用場景\"}],\"：評估輸出的事實正確性、安全性（是否包含有害內容）、格式遵循度等客觀標準。\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"2.3 自動化評測工作流 (Automated Evaluation Workflow)\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"一個典型的 LLM-as-a-Judge 自動化評測工作流包含以下步驟：\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"準備測試數據集 (Prepare Test Dataset)\"}],\"：收集一組代表真實使用場景的輸入數據（例如使用者問題、任務描述）。對於需要 Reference 的評測，也需準備對應的黃金標準答案。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Candidate 模型生成輸出 (Candidate Generation)\"}],\"：\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"將測試數據集中的每個輸入傳遞給待評測的 Candidate LLM。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"收集 Candidate LLM 針對每個輸入生成的輸出。\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Judge 模型評分 (Judge Evaluation)\"}],\"：\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"對於測試數據集中的每個輸入-輸出對，將以下資訊傳遞給 Judge LLM：\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"原始輸入 (Original Input)\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Candidate LLM 的輸出 (Candidate Output)\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"詳細的評分標準 (Rubrics)\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"（可選）參考答案 (Reference Answer)\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Judge LLM 根據這些資訊，生成一個結構化的評分（例如 JSON 格式），其中包含分數和解釋其判斷的理由（Chain-of-Thought）[6]。\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"數據彙整與分析 (Data Aggregation \u0026 Analysis)\"}],\"：\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"收集所有 Judge LLM 生成的評分結果。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"計算各種評測指標的平均分、分佈等統計數據。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"分析 Judge LLM 給出的理由，找出 Candidate 模型的優點和缺點。\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"報告生成與可視化 (Report Generation \u0026 Visualization)\"}],\"：\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"將分析結果整理成易讀的報告，例如包含雷達圖、趨勢圖、分數分佈圖等，直觀展示 Candidate 模型的性能。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"這份報告可以作為開發者改進模型的依據。\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"迭代優化 (Iterative Optimization)\"}],\"：\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"根據評測報告的結果，開發者調整 Candidate 模型的提示詞、參數或甚至進行微調。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"重複上述步驟，直到 Candidate 模型的性能達到預期目標。\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"3. 評分標準 (Evaluation Rubrics) 設計\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"設計一套清晰、客觀且全面的評分標準（Rubrics）是 LLM-as-a-Judge 成功的關鍵。Rubrics 應該明確地告訴 Judge LLM「什麼是好的輸出」，以及不同分數等級的具體含義 [7]。\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"3.1 Rubric 結構\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"一個有效的 Rubric 通常包含以下要素：\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Criterion (評測標準)\"}],\"：定義評估的維度，例如「邏輯連貫性」、「數據準確度」、「語氣合適性」、「格式遵循度」等。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Scale (評分量表)\"}],\"：定義每個標準的評分範圍（例如 1-5 分），並為每個分數等級提供詳細的描述。例如：\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"5 分 (優秀)\"}],\"：輸出完全符合要求，無可挑剔。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"3 分 (一般)\"}],\"：輸出基本符合要求，但存在一些小瑕疵。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"1 分 (差)\"}],\"：輸出完全不符合要求，或包含嚴重錯誤。\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Examples (範例)\"}],\"：提供給 Judge LLM 的 Few-shot 範例，展示在不同分數等級下，一個「好」的輸出和一個「壞」的輸出分別是什麼樣子。這有助於 Judge LLM 更好地理解評分標準 [8]。\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"3.2 關鍵評測指標\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"針對 LLM 的輸出，常見的評測指標包括：\"}],\"\\n\",[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"指標名稱\"}],[\"$\",\"th\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"描述\"}],[\"$\",\"th\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"評測方式\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"strong\",null,{\"children\":\"Faithfulness (忠實度)\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"輸出內容是否完全基於提供的原始上下文或資料，沒有產生幻覺。\"}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"Judge 檢查輸出中的每個事實性陳述是否能在原始輸入中找到依據。\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"strong\",null,{\"children\":\"Relevance (相關性)\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"輸出內容是否直接、完整地回答了使用者的問題或完成了任務。\"}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"Judge 判斷輸出是否偏離主題，或是否遺漏了關鍵資訊。\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"strong\",null,{\"children\":\"Correctness (正確性)\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"輸出中包含的事實性數據、邏輯判斷是否準確無誤。\"}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"Judge 根據 Reference 或其自身知識判斷事實性錯誤。\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"strong\",null,{\"children\":\"Coherence (連貫性)\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"輸出內容的邏輯是否清晰、流暢，各部分之間是否有良好的銜接。\"}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"Judge 評估輸出的組織結構、段落銜接和整體可讀性。\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"strong\",null,{\"children\":\"Conciseness (簡潔性)\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"輸出是否在不犧牲資訊完整性的前提下，盡可能地簡潔明瞭。\"}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"Judge 判斷輸出是否存在冗餘、重複或不必要的細節。\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"strong\",null,{\"children\":\"Safety (安全性)\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"輸出是否包含有害、偏見、歧視或不當的內容。\"}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"Judge 檢查輸出是否違反預設的安全準則。\"}]]}]]}]]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"4. Prerequisites\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"要實作 LLM-as-a-Judge 評測框架，您需要具備以下環境和知識：\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Python 環境\"}],\"：建議使用 Python 3.9 或更高版本。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"LLM API 存取\"}],\"：需要至少兩個 LLM 的 API 存取權限：一個作為 Judge（通常是最強的模型，如 GPT-4o），另一個作為 Candidate（待測模型）。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"LLM 框架知識\"}],\"：熟悉 LangChain、DSPy 或 Semantic Kernel 等 LLM 開發框架，以便於構建 Candidate 和 Judge 的互動邏輯。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"數據處理能力\"}],\"：能夠處理測試數據集，包括輸入、輸出和可選的參考答案。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"評估框架\"}],\"：了解並可能需要使用專門的 LLM 評估框架，如 G-Eval、Prometheus 或 DeepEval。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"數據可視化工具\"}],\"：熟悉 Matplotlib、Seaborn 或其他數據可視化庫，用於生成評測報告。\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"5. Implementation / Code Example\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"本節將提供一個概念性的 Python 程式碼範例，展示如何使用 LLM-as-a-Judge 評估一個簡單的「股票分析 AI」的回答品質。我們將使用一個較小的模型作為 Candidate，並使用 GPT-4o 作為 Judge。\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"5.1 專案初始化與安裝\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"className\":\"language-bash\",\"children\":\"mkdir llm-judge-example\\ncd llm-judge-example\\npip install openai python-dotenv # 假設使用 OpenAI API\\n\"}]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"5.2 配置 LLM API 金鑰\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"創建 \",[\"$\",\"code\",null,{\"children\":\".env\"}],\" 檔案來儲存您的 API 金鑰：\"]}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"className\":\"language-dotenv\",\"children\":\"OPENAI_API_KEY=your_openai_api_key_here\\n\"}]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":[\"5.3 核心程式碼 (\",[\"$\",\"code\",null,{\"children\":\"evaluate_stock_ai.py\"}],\")\"]}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"className\":\"language-python\",\"children\":\"$17\"}]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"5.4 程式碼說明\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"EVALUATION_RUBRIC\"}]}],\"：這是一個多行字串，定義了給 Judge LLM 的評分標準。它明確要求 Judge 以 JSON 格式輸出，並包含 \",[\"$\",\"code\",null,{\"children\":\"logic_score\"}],\"、\",[\"$\",\"code\",null,{\"children\":\"data_accuracy\"}],\"、\",[\"$\",\"code\",null,{\"children\":\"completeness\"}],\"、\",[\"$\",\"code\",null,{\"children\":\"reasoning\"}],\" 和 \",[\"$\",\"code\",null,{\"children\":\"overall_verdict\"}],\" 等欄位。這是 LLM-as-a-Judge 的核心，將人類的評分邏輯轉化為 AI 可理解的指令 [7]。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"candidate_stock_analyzer\"}]}],\"：模擬一個待評測的股票分析 AI。在實際應用中，這會是一個對您自己開發的 LLM 應用程式的 API 調用，或者是一個使用較小模型（如 Llama 3）的推理過程。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"judge_llm_evaluation\"}]}],\"：這是 Judge LLM 的核心功能。它使用 \",[\"$\",\"code\",null,{\"children\":\"gpt-4o\"}],\" 作為考官，接收原始問題和 Candidate 的回應，並根據 \",[\"$\",\"code\",null,{\"children\":\"EVALUATION_RUBRIC\"}],\" 進行評估。\",[\"$\",\"code\",null,{\"children\":\"response_format={\\\"type\\\": \\\"json_object\\\"}\"}],\" 強制 LLM 輸出 JSON 格式，確保結果的可解析性 [6]。\",[\"$\",\"code\",null,{\"children\":\"temperature=0.0\"}],\" 則用於減少 Judge LLM 的隨機性，使其評分更穩定。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":[[\"$\",\"code\",null,{\"children\":\"main\"}],\" 函數\"]}],\"：定義了一組測試案例，並循環執行評測工作流。它首先呼叫 \",[\"$\",\"code\",null,{\"children\":\"candidate_stock_analyzer\"}],\" 獲取回應，然後將回應傳遞給 \",[\"$\",\"code\",null,{\"children\":\"judge_llm_evaluation\"}],\" 進行評分。最後，它彙總並列印出評測報告摘要。\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"6. Parameters / API Reference\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"本節將基於上述範例，抽象出實作 LLM-as-a-Judge 時可能涉及的關鍵參數和介面。\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":[\"6.1 \",[\"$\",\"code\",null,{\"children\":\"EVALUATION_RUBRIC\"}],\" 結構 (傳遞給 Judge LLM 的提示詞)\"]}],\"\\n\",[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"欄位名稱\"}],[\"$\",\"th\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"類型\"}],[\"$\",\"th\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"描述\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"logic_score\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"int\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"評估輸出的邏輯性，通常為 1-5 分。\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"data_accuracy\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"str\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"評估數據的準確度，通常為 \\\"Pass\\\" 或 \\\"Fail\\\"。\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"completeness\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"int\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"評估輸出的完整性，通常為 1-5 分。\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"reasoning\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"str\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"Judge LLM 給出評分的詳細理由（Chain-of-Thought）。\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"overall_verdict\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"str\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"Judge LLM 對輸出的總體評價。\"}]]}]]}]]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":[\"6.2 \",[\"$\",\"code\",null,{\"children\":\"candidate_stock_analyzer\"}],\" 介面 (概念性)\"]}],\"\\n\",[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"參數名稱\"}],[\"$\",\"th\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"類型\"}],[\"$\",\"th\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"描述\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"question\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"str\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"使用者提出的股票分析問題。\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"strong\",null,{\"children\":\"返回值\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"str\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"Candidate LLM 生成的股票分析報告。\"}]]}]]}]]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":[\"6.3 \",[\"$\",\"code\",null,{\"children\":\"judge_llm_evaluation\"}],\" 介面\"]}],\"\\n\",[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"參數名稱\"}],[\"$\",\"th\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"類型\"}],[\"$\",\"th\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"描述\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"question\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"str\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"原始問題，作為 Judge LLM 評估的上下文。\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"ai_response\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"str\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"Candidate LLM 生成的分析報告。\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"strong\",null,{\"children\":\"返回值\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":[\"$\",\"code\",null,{\"children\":\"Dict[str, Any]\"}]}],[\"$\",\"td\",null,{\"style\":{\"textAlign\":\"left\"},\"children\":\"Judge LLM 根據 Rubric 生成的 JSON 格式評估結果。\"}]]}]]}]]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"7. Notes \u0026 Best Practices\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"選擇合適的 Judge LLM\"}],\"：始終選擇當前能力最強、最穩定的 LLM 作為 Judge。其推理能力和遵循指令的能力直接影響評測結果的可靠性。GPT-4o 或 Claude 3.5 Sonnet 是目前較好的選擇 [4]。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"設計清晰的 Rubrics\"}],\"：評分標準必須極其清晰、具體，並包含詳細的評分量表描述和範例。模糊的 Rubrics 會導致 Judge LLM 評分不一致或不準確 [7]。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"強制結構化輸出\"}],\"：要求 Judge LLM 以 JSON 或其他結構化格式輸出評分結果，這便於後續的程式化解析和數據分析。利用 \",[\"$\",\"code\",null,{\"children\":\"response_format\"}],\" 參數（如 OpenAI API）可以有效實現這一點 [6]。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"利用 Chain-of-Thought (CoT)\"}],\"：在提示詞中要求 Judge LLM 提供其評分理由（Reasoning）。這不僅增加了評測過程的透明度，也幫助開發者理解 Candidate 模型失敗的原因，從而更好地進行調試和改進 [6]。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"溫度參數設置\"}],\"：將 Judge LLM 的 \",[\"$\",\"code\",null,{\"children\":\"temperature\"}],\" 參數設置為 0.0 或接近 0，以減少其生成結果的隨機性，確保評分的一致性和穩定性。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"評測數據集的代表性\"}],\"：確保測試數據集能夠全面覆蓋 Candidate LLM 的預期使用場景和邊界情況。數據集的品質直接影響評測結果的有效性。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"人類校驗 (Human Validation)\"}],\"：即使是 LLM-as-a-Judge，也建議定期進行小規模的人工校驗，以確保 Judge LLM 的評分與人類專家的判斷保持一致。這有助於發現 Judge LLM 可能存在的偏見或理解偏差 [1]。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"成本與效率平衡\"}],\"：使用最強的 LLM 作為 Judge 可能會產生較高的 API 成本。在實際應用中，可以考慮分層評測：先用較便宜的 Judge 進行初步篩選，再用最強的 Judge 進行關鍵評估，或者對評測頻率進行控制。\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"8. 為什麼選擇這種方式？\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"將 LLM 作為評審（LLM-as-a-Judge）是 AI 應用開發從「玩具」走向「產品」的關鍵一步，其核心價值在於：\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"實現 AI 評測的自動化與規模化\"}],\"：傳統的人工評測耗時耗力，難以應對快速迭代的 LLM 應用。LLM-as-a-Judge 能夠在數分鐘內完成數百甚至數千個輸出的評測，極大地提升了評測效率，使得開發者能夠在每次代碼提交後都運行完整的評測，實現持續整合與持續部署（CI/CD）的 AI 開發流程 [1]。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"提供客觀且一致的評分標準\"}],\"：人類評審容易受到疲勞、情緒和主觀判斷的影響，導致評分不一致。而經過精心設計提示詞的 Judge LLM，能夠始終如一地遵循預設的 Rubrics 進行評分，提供更客觀、更穩定的評測結果 [7]。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"加速模型迭代與優化\"}],\"：透過自動化評測，開發者可以快速獲得關於模型性能的量化反饋。Judge LLM 提供的詳細評分理由（Chain-of-Thought）能夠幫助開發者精確定位 Candidate 模型的弱點，從而更有針對性地調整提示詞、模型參數或進行微調，加速模型的迭代和優化過程 [6]。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"降低評測成本\"}],\"：雖然使用高階 LLM 作為 Judge 會產生 API 費用，但相較於聘請大量人類專家進行大規模評測，其總體成本通常會顯著降低。這使得中小型團隊也能負擔得起高品質的 AI 評測 [1]。\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"提升產品級應用的信心\"}],\"：在將 AI 應用部署到生產環境之前，開發者需要對其性能有足夠的信心。LLM-as-a-Judge 提供了一個可靠的、可重複的評測框架，確保每次發布的模型都達到了預期的品質標準，從而提升了產品的穩定性和使用者滿意度。\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"參考資料\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"[1] Monte Carlo Data. (2025, November 7). \",[\"$\",\"em\",null,{\"children\":\"LLM-As-Judge: 7 Best Practices \u0026 Evaluation Templates\"}],\". Retrieved from \",[\"$\",\"a\",null,{\"href\":\"https://www.montecarlodata.com/blog-llm-as-judge/\",\"children\":\"https://www.montecarlodata.com/blog-llm-as-judge/\"}]]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"[2] Confident AI. (n.d.). \",[\"$\",\"em\",null,{\"children\":\"LLM-as-a-Judge Simply Explained: The Complete Guide to Run LLM Evaluations\"}],\". Retrieved from \",[\"$\",\"a\",null,{\"href\":\"https://www.confident-ai.com/blog/why-llm-as-a-judge-is-the-best-llm-evaluation-method\",\"children\":\"https://www.confident-ai.com/blog/why-llm-as-a-judge-is-the-best-llm-evaluation-method\"}]]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"[3] Evidently AI. (2025, July 23). \",[\"$\",\"em\",null,{\"children\":\"LLM-as-a-judge: a complete guide to using LLMs for evaluations\"}],\". Retrieved from \",[\"$\",\"a\",null,{\"href\":\"https://www.evidentlyai.com/llm-guide/llm-as-a-judge\",\"children\":\"https://www.evidentlyai.com/llm-guide/llm-as-a-judge\"}]]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"[4] arXiv. (2024, November 23). \",[\"$\",\"em\",null,{\"children\":\"A Survey on LLM-as-a-Judge\"}],\". Retrieved from \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/html/2411.15594v1\",\"children\":\"https://arxiv.org/html/2411.15594v1\"}]]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"[5] Reddit. (2026, January 6). \",[\"$\",\"em\",null,{\"children\":\"BEST LLM-as-a-Judge Practices from 2025\"}],\". Retrieved from \",[\"$\",\"a\",null,{\"href\":\"https://www.reddit.com/r/LangChain/comments/1q59at8/best_llmasajudge_practices_from_2025/\",\"children\":\"https://www.reddit.com/r/LangChain/comments/1q59at8/best_llmasajudge_practices_from_2025/\"}]]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"[6] Confident AI. (2025, October 10). \",[\"$\",\"em\",null,{\"children\":\"G-Eval Simply Explained: LLM-as-a-Judge for LLM Evaluation\"}],\". Retrieved from \",[\"$\",\"a\",null,{\"href\":\"https://www.confident-ai.com/blog/g-eval-the-definitive-guide\",\"children\":\"https://www.confident-ai.com/blog/g-eval-the-definitive-guide\"}]]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"[7] Towards Data Science. (2025, June 19). \",[\"$\",\"em\",null,{\"children\":\"LLM-as-a-Judge: A Practical Guide\"}],\". Retrieved from \",[\"$\",\"a\",null,{\"href\":\"https://towardsdatascience.com/llm-as-a-judge-a-practical-guide/\",\"children\":\"https://towardsdatascience.com/llm-as-a-judge-a-practical-guide/\"}]]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"[8] Microsoft Learn. (2024, June 24). \",[\"$\",\"em\",null,{\"children\":\"Evaluating the performance of LLM summarization prompts with G-Eval\"}],\". Retrieved from \",[\"$\",\"a\",null,{\"href\":\"https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/generative-ai/working-with-llms/evaluation/g-eval-metric-for-summarization\",\"children\":\"https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/generative-ai/working-with-llms/evaluation/g-eval-metric-for-summarization\"}]]}],\"\\n\"]}]]\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nb:null\n"])</script><script>self.__next_f.push([1,"14:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"【AI 評測領域】LLM-as-a-Judge：如何用 AI 來面試 AI？ | 子yee 萬事屋 | 子yee\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"深入探討 LLM-as-a-Judge 評測框架，教學如何利用高階 LLM 作為考官，自動評估其他 LLM 的輸出品質，實現 AI 應用從原型到產品的關鍵飛躍。\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"子yee\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"子yee 萬事屋, 台股查詢, 自選股, 技術小工具, 股票資訊平台, 技術顧問, 自動化工具\"}],[\"$\",\"meta\",\"4\",{\"name\":\"google-site-verification\",\"content\":\"adHIcDQiasHY4YzPlrpmSSPKl7Oj1WxrPJ_4GV4PQcM\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:title\",\"content\":\"【AI 評測領域】LLM-as-a-Judge：如何用 AI 來面試 AI？\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:description\",\"content\":\"深入探討 LLM-as-a-Judge 評測框架，教學如何利用高階 LLM 作為考官，自動評估其他 LLM 的輸出品質，實現 AI 應用從原型到產品的關鍵飛躍。\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:image\",\"content\":\"https://qwer820921.github.io/images/img15.jpg\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:image:alt\",\"content\":\"【AI 評測領域】LLM-as-a-Judge：如何用 AI 來面試 AI？\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:title\",\"content\":\"【AI 評測領域】LLM-as-a-Judge：如何用 AI 來面試 AI？\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:description\",\"content\":\"深入探討 LLM-as-a-Judge 評測框架，教學如何利用高階 LLM 作為考官，自動評估其他 LLM 的輸出品質，實現 AI 應用從原型到產品的關鍵飛躍。\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:image\",\"content\":\"https://qwer820921.github.io/images/img15.jpg\"}],[\"$\",\"link\",\"16\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"64x64\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"e:{\"metadata\":\"$14:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>